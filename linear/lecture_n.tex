\chapter{Лекция N}
Вспомним: рассматривается система вида
\begin{equation}
    \dot{x}(t) = A(t) x(t) + B(t) u (t) + f(t),
\end{equation}
мы пытаемся перевести её из начального состояния $x^0$ в конечное $x^1$:
\begin{equation}
    x(t_0) = x^0 \to x(t_1) = x^1,
\end{equation}
минимизируя при этом норму управления в пространстве $\L_2$:
\begin{equation}
    \mathcal{J}(u(\cdot)) = \norm{u(\cdot)}_{\L_2} \to \inf\limits_{u(\cdot)}
\end{equation}

Данной постановке соответствует задача моментов
\begin{equation}\tag{ЗМ}
    \int_{t_0}^{t_1} H(t_1, t) u(t) dt = c,
\end{equation}
где $H(t_1, t) = \X(t_1, t) B(t)$.

\begin{bf}Внимание! В этой лекции волевым усилием давайте во избежание дальнейшей путаницы начнём обозначать множество достижимости для задачи моментов за $\mathscr{H}_{\mu}^0$ вместо $\mathscr{X}_{\mu}^0$, чтобы точно не было никаких мыслей про то, что икс там и в обычном уравнении - это что-то очень похожее.\end{bf}

Пусть управление ограничено некоторым абстрактным значением $\mu$. Множеством достижимости для задачи моментов (ЗМ) при ограничении $\norm{u(\cdot)}_{\L_2} \leqslant \mu$ договорились называть
\begin{equation}
    \H_{\mu}^0 = \left\{ \int_{t_0}^{t_1} H(t_1, t) u(t) dt \mid \norm{u(\cdot)}_{\L_2} \leqslant \mu \right\}.
\end{equation}

Затем мы нашли опорную функцию множества достижимости этой ЗМ:
$$
\rho(l, \H_{\mu}^0) = \mu \norm{H'(t_1, \cdot)l}_{\L_2} = \mu \sqrt{\scalar{l}{Wl}},
$$
где $W = W(t_1, t_0) = \int_{t_0}^{t_1} H(t_1, t) H'(t_1, t) dt$ --- матрица управляемости.

\section{Случай полной управляемости ($\abs{W} \neq 0$) --- геометрический смысл решения}
Если $\abs{W} \neq 0$ (что эквивалентно неравенству $W > 0$, $W = W'$), то оптимальное $\mu$ находится из соотношения
$$
\mu^* = \sqrt{\scalar{c}{W^{-1}c}},
$$
а оптимальное управление, соответственно, равно
$$
u^*(t) = H'(t_1,t) W^{-1}(t_1, t_0) c.
$$

Обсудим геометрическую интерпретацию полученного решения.

Предположим, что мы ищем управление $u(\cdot)$ \textit{приближённо} в классе кусочно~-постоянных функций:
$$
u(t) = \left\{
    \begin{aligned}
        \hat{u}^1, & \;\; t \in [t_0, \tau_1],\\
        \hat{u}^j, & \;\; t \in (\tau_{j-1}, \tau_{j}], \; j = \overline{2, N},
    \end{aligned}
\right.
$$
$\hat{u}^j \in \R^m$. Тогда каждое из рассматриваемых управлений определяется вектором
$$
u(\cdot) \leftrightarrow \begin{bmatrix}
    \hat{u}^1_1 \\ \ldots \\ \hat{u}^1_m \\ \vdots \\ \hat{u}^N_1 \\ \ldots \\ \hat{u}^N_m
\end{bmatrix} = \hat{u} \in \R^{m \times N}.
$$

Пусть для простоты $m = 1$ --- то есть управление скалярнозначное. Тогда кусочно-постоянная его аппроксимация (на $N$ отрезках сетки) будет выглядеть как
$$
\hat{u} = \begin{bmatrix}
    \hat{u}^1 \\ \vdots \\ \hat{u}^N
\end{bmatrix}
$$
Тогда наша (ЗМ) трансформируется в следующую задачу:
$$
\sum\limits_{j=1}^{N} \left[ \int\limits_{\tau_{j-1}}^{\tau_j} H(t_1, t) dt \right] \hat{u}^j = c
$$
Обозначим (при $m = 1$ выполнено ${H(t_1, t) \in \R^{n \times 1}}$)
$$
\int\limits_{\tau_{j-1}}^{\tau_j} H(t_1, t) dt = [\hat{g}^j_1, \ldots, \hat{g}^j_n]'
$$
Подставим $c = [c_1  \ldots c_n]'$ $\thus$ получаем СЛАУ относительно $\hat{u}^j$:
$$
\sum\limits_{j=1}^{N} \hat{g}^j_i \hat{u}^j = c_i, \; i = \overline{1, n}.
$$

Перепишем эту систему в другом виде.
Сгруппируем компоненты $\hat{g}^j_i$ по координатам $i$, обозначим:
$$
\hat{g}_i = [\hat{g}^1_i, \ldots,  \hat{g}^N_i]'
$$
\textit{(если уже успели запутаться: $i \leqslant n = \dim(x)$, а $N$ --- количество отрезков, которые мы выбрали для построения кусочно-постоянной аппроксимации управления)}.

Тогда наша СЛАУ перепишется в следующем виде \textit{(уже без $i = \overline{1, n}$)}.
\begin{equation} \tag{$\star$}
\left\{
    \begin{aligned}
        & \scalar{\hat{g}_1}{\hat{u}} = c_1, \\
        & \ldots\\
        & \scalar{\hat{g}_n}{\hat{u}} = c_n,
    \end{aligned}
\right.
\end{equation}
и минимизацию мы будем проводить для функционала (вводим равномерную сетку $\Delta t = (t_1 - t_0) / N$)
$$
\mathcal{J}(u(\cdot)) = \sqrt{\Delta t} \norm{\hat{u}} \to \min.
$$

Пусть теперь $n = 2, N = 3$.